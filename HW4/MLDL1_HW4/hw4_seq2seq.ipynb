{"cells":[{"cell_type":"markdown","metadata":{"id":"EDxtMC2g66gQ"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vj2CXov7JJqq"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcKp4bZiJwut"},"outputs":[],"source":["\"\"\"\n","Change directory to where this file is located\n","\"\"\"\n","# %cd 'COPY&PASTE FILE DIRECTORY HERE'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHKo6dP6eEO6"},"outputs":[],"source":["import math\n","import random\n","from pathlib import Path\n","import sys\n","\n","from data.data import prepareData\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["\"\"\"\n","import modules you need\n","\"\"\"\n"],"metadata":{"id":"5U2jKstSrVfj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kz2VM-9MIyKe"},"source":["## Util"]},{"cell_type":"markdown","metadata":{"id":"8qCY42PE0kRj"},"source":["**Do NOT Modify** code blocks in this section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OOnSsL1EeG85"},"outputs":[],"source":["SEED = 1234\n","DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","random.seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHo7XkIGIz2z"},"outputs":[],"source":["def train(model, iterator, optimizer, loss_fn, clip):\n","    model.train()\n","    epoch_loss = 0\n","\n","    for i, batch in enumerate(iterator):\n","        src = batch[0].to(DEVICE)\n","        trg = batch[1].to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(src, trg)\n","        loss = loss_fn(output, trg)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2-jeXr-I1yP"},"outputs":[],"source":["def evaluate(model, iterator, loss_fn):\n","    model.eval()\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            src = batch[0].to(DEVICE)\n","            trg = batch[1].to(DEVICE)\n","            output = model(src, trg)\n","            loss = loss_fn(output, trg)\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"]},{"cell_type":"code","source":["def plot_history(history):\n","    plt.figure(figsize=(2 * 13, 4))\n","    plt.subplot(1, 5, 1)\n","    plt.title(\"Training and Validation Loss\")\n","    plt.plot(history['train_PPL'], label=\"train_PPL\")\n","    plt.plot(history['val_PPL'], label=\"val_PPL\")\n","    plt.xlabel(\"iterations\")\n","    plt.ylabel(\"PPL\")\n","    plt.legend()\n","    plt.subplot(1, 5, 2)\n","    plt.title(\"Learning Rate\")\n","    plt.plot(history['lr'], label=\"learning rate\")\n","    plt.xlabel(\"iterations\")\n","    plt.ylabel(\"LR\")\n","    plt.show()"],"metadata":{"id":"gnb-nEET7aEe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5PgCsIyawXoN"},"source":["## Dataset & Dataloader"]},{"cell_type":"markdown","metadata":{"id":"40ZOR80S0wet"},"source":["**Do NOT Modify** code blocks in this section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwwJGiyETHsL"},"outputs":[],"source":["MAX_LENGTH = 10\n","BATCH_SIZE = 64\n","\n","TRAIN_RATIO = 0.7 # train dataset ratio, should be a float in (0, 0.8]\n","VALID_RATIO = 0.8 - TRAIN_RATIO\n","\n","SOS_token = 0\n","EOS_token = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fePBsU2GKoaI"},"outputs":[],"source":["class TranslateDataset(Dataset):\n","    def __init__(self, max_length=10, fra2eng=True):\n","        self.input_lang, self.output_lang, self.pairs = prepareData('eng', 'fra', max_length=max_length, reverse=fra2eng)\n","        self.max_length = max_length\n","        self.input_lang.addWord('PAD')\n","        self.output_lang.addWord('PAD')\n","        self.input_lang_pad = self.input_lang.word2index['PAD']\n","        self.output_lang_pad = self.output_lang.word2index['PAD']\n","\n","        print(\"\\n\")\n","        print(\"This is data example\")\n","        print(random.choice(self.pairs))\n","\n","        print(\"\\n\")\n","        print(\"This is index of PAD token for each language\")\n","        print(f\"fra {self.output_lang.word2index['PAD']}\")\n","        print(f\"eng {self.input_lang.word2index['PAD']}\")\n","\n","    def __len__(self):\n","        return len(self.pairs)\n","\n","    def __getitem__(self, idx):\n","        pair = self.pairs[idx]\n","        x, y = self._tensorsFromPair(pair)\n","        return x, y\n","\n","    def _tensorFromSentence(self, lang, sentence):\n","        indexes = [lang.word2index[word] for word in sentence.split(' ')]\n","        indexes.append(EOS_token)\n","        return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n","\n","    def _tensorsFromPair(self, pair):\n","        input_tensor = self._tensorFromSentence(self.input_lang, pair[0])\n","        target_tensor = self._tensorFromSentence(self.output_lang, pair[1])\n","        return (input_tensor, target_tensor)\n","\n","    def collate_fn(self, data):\n","        x_batch = []; y_batch = []\n","\n","        for x, y in data:\n","            if x.shape[0] < self.max_length-1:\n","                x = torch.cat([x, self.input_lang_pad*torch.ones((self.max_length-1 - x.shape[0], 1), dtype=x.dtype)])\n","            elif x.shape[0] > self.max_length-1:\n","                x = x[:self.max_length-1]\n","            if y.shape[0] < self.max_length-1:\n","                y = torch.cat([y, self.output_lang_pad*torch.ones((self.max_length-1 - y.shape[0], 1), dtype=y.dtype)])\n","            elif y.shape[0] > self.max_length-1:\n","                y = y[:self.max_length-1]\n","\n","            x_batch.append(torch.cat([torch.tensor([SOS_token]), x.squeeze(1)]))\n","            y_batch.append(torch.cat([torch.tensor([SOS_token]), y.squeeze(1)]))\n","\n","        return torch.stack(x_batch), torch.stack(y_batch)\n","\n","dataset = TranslateDataset(max_length=MAX_LENGTH)\n","\n","train_size = int(len(dataset)*TRAIN_RATIO)\n","valid_size = int(len(dataset)*VALID_RATIO)\n","train_data, valid_data, test_data = random_split(dataset, [train_size, valid_size, len(dataset)-(train_size+valid_size)],)\n","print(\"\\n\")\n","print(f\"This is dataset_size: {len(dataset)}\")\n","print(f\"train_size: {train_size}\")\n","print(f\"valid_data: {valid_size}\")\n","print(f\"test_data: {len(test_data)}\")\n","\n","train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n","valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"A5xyf2mHuhmX"},"source":["## Implement LSTM Seq2Seq Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1MM6lL95JcDa"},"outputs":[],"source":["class LSTMEncoder(nn.Module):\n","\n","    def __init__(self, in_dim, emb_dim, hid_dim):\n","        super(LSTMEncoder, self).__init__()\n","\n","        self.embedding = nn.Embedding(in_dim, emb_dim)\n","        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, num_layers=1, batch_first=True)\n","\n","    def forward(self, input, hidden, cell):\n","        '''\n","        Q2 - (a)\n","        Implement forward method of LSTM Encoder Module\n","\n","        INPUT\n","        - input: input sentence, (B, max_len)\n","        - hidden: initialized hidden state, (1, B, hid_dim)\n","        - cell: initialized cell state, (1, B, hid_dim)\n","\n","        OUTPUT\n","        What to be returned depends on your implementation of LSTMSeq2Seq. (Q2 - (b))\n","        Feel free to return outputs you need. (e.g. hidden states of encoder, etc.)\n","        '''\n","        ################### YOUR CODE ###################\n","\n","        return None\n","        #################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPQnZdz5KKnN"},"outputs":[],"source":["class AttnLSTMDecoder(nn.Module):\n","\n","    def __init__(self, emb_dim, hid_dim, out_dim, dropout, enc_hiddens=None):\n","        super(AttnLSTMDecoder, self).__init__()\n","        self.enc_hiddens = enc_hiddens # encoder output\n","        self.dropout = dropout\n","\n","        self.embedding = nn.Embedding(out_dim, emb_dim)\n","        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, batch_first=True)\n","        self.fc = nn.Linear(hid_dim + hid_dim, hid_dim)\n","        self.tanh = nn.Tanh()\n","        self.classifier = nn.Linear(hid_dim, out_dim)\n","\n","    def forward(self, input, hidden, cell):\n","\n","        '''\n","        Q2 - (a)\n","        Implement forward method of LSTM Decoder Module with dot-product attention\n","        Before implementing LSTM layer, make sure to feed the concatenated input into Linear and tanh activation layer.\n","        This will allow the concatenated input to be resized from (B, hid_dim + hid_dim) into (B, hid_dim)\n","\n","        INPUT\n","        - input: a token of input sentence (B, 1)\n","        - hidden: previous hidden state (B, hid_dim)\n","        - cell: previous cell state (1, B, hid_dim)\n","\n","        OUTPUT\n","        What to be returned depends on your implementation of LSTMSeq2Seq. (Q2 - (b))\n","        Feel free to return outputs you need.\n","        Some examples below\n","        - predicted token embedding (N, emb_dim)\n","        - current hidden state\n","        - current cell state\n","        '''\n","\n","        ################### YOUR CODE ###################\n","        query = hidden # set query to calculate attention\n","\n","        return None\n","        #################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zJsJ3p2NLD6c"},"outputs":[],"source":["class LSTMSeq2Seq(nn.Module):\n","    def __init__(self, in_dim, out_dim, emb_dim, hid_dim, device, dropout):\n","        super(LSTMSeq2Seq, self).__init__()\n","\n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        self.emb_dim = emb_dim\n","        self.hid_dim = hid_dim\n","        self.device = device\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.encoder = LSTMEncoder(in_dim, emb_dim, hid_dim)\n","        self.decoder = AttnLSTMDecoder(emb_dim, hid_dim, out_dim, dropout)\n","\n","    def forward(self, src, trg):\n","        '''\n","        Q2 - (b)\n","        Implement forward method of LSTM Seq2Seq Module\n","        (Decoder module should attend encoder's outputs using dot product.)\n","\n","        INPUT\n","        - src: source language batched data (B, max_len)\n","        - trg: target language batched data (B, max_len)\n","\n","        OUTPUT\n","        - output of one-hot prediction (B, out_dim, max_len)\n","        '''\n","        ################### YOUR CODE ###################\n","        batch_size, mx_len = src.shape\n","\n","        # Encoder (start from zero-hidden & zero-cell states)\n","\n","\n","        # Decoder\n","        self.decoder.enc_hiddens = None # set encoder's hidden states\n","        outputs = torch.zeros(mx_len, batch_size, dataset.output_lang.n_words).to(self.device) # to store each decoder's output\n","\n","        for t in range(1, mx_len): # for each t'th token, get decoder outputs\n","            continue\n","\n","\n","        return None\n","        #################################################"]},{"cell_type":"markdown","metadata":{"id":"cu3WP3mYw3NV"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4YKhRe9d9qC"},"outputs":[],"source":["'''\n","Q2 - (c)\n","Train your Seq2Seq model and plot perplexities and learning rates.\n","Upon successful training, the test perplexity should be less than 7.\n","Briefly report your hyperparameters and results on test dataset.\n","Make sure your results are printed in your submitted file.\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1QQgN03XecUV"},"outputs":[],"source":["# experiment various methods for better performance\n","# you can modify the codes in this block\n","in_dim = dataset.input_lang.n_words\n","out_dim = dataset.output_lang.n_words\n","hid_dim = 256\n","emb_dim = 256\n","dropout = 0.1\n","learning_rate = 0.1\n","N_EPOCHS = 100\n","valid_every=5\n","best_valid_loss = float('inf')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = LSTMSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss(ignore_index = dataset.output_lang_pad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbSR6BZKf-6L"},"outputs":[],"source":["# Train your model\n","# you can modify the codes in this block\n","history = {'train_PPL':[], 'val_PPL':[], 'lr':[]}\n","\n","for epoch in range(N_EPOCHS):\n","    train_loss = train(model, train_dataloader, optimizer, loss_fn, 1)\n","\n","    print(f'Epoch: {epoch+1:02}')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","\n","    if epoch%valid_every==0:\n","        print(\"==========================\")\n","        valid_loss = evaluate(model, valid_dataloader, loss_fn)\n","\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            model.decoder.t=0\n","            torch.save(model.state_dict(), 'lstm-attn-model.pt')\n","        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n","\n","        history['train_PPL'].append(math.exp(train_loss))\n","        history['val_PPL'].append(math.exp(valid_loss))\n","        history['lr'].append(optimizer.param_groups[0]['lr'])\n","\n","plot_history(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBXKAKZo2lSS"},"outputs":[],"source":["# Test your model\n","torch.save(model.state_dict(), 'lstm-attn-model.pt')\n","loaded_model = LSTMSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n","loaded_model.load_state_dict(torch.load('lstm-attn-model.pt'))\n","\n","test_loss = evaluate(loaded_model, test_dataloader, loss_fn)\n","print(f'\\t Test. Loss: {valid_loss:.3f} |  Test. PPL: {math.exp(valid_loss):7.3f}')"]},{"cell_type":"markdown","source":["Briefly report your hyperparameters and results on test datasets.  \n","\n","You Answer :"],"metadata":{"id":"nfdDVw99VvV-"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}